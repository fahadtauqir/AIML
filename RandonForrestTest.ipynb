{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl3nY8GmZOTa"
      },
      "outputs": [],
      "source": [
        "import sys, matplotlib, pandas, sklearn, seaborn\n",
        "\n",
        "print(f'Python: {sys.version}')\n",
        "print(f'matplotlib: {matplotlib.__version__}')\n",
        "print(f'pandas: {pandas.__version__}')\n",
        "print(f'sklearn: {sklearn.__version__}')\n",
        "print(f'seaborn: {seaborn.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "id": "V4eNre_ZaViM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "# Data Manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from   pandas import DataFrame\n",
        "\n",
        "# Data Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine Learning\n",
        "from   sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
        "from   sklearn.impute import SimpleImputer\n",
        "from   sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from   sklearn.linear_model import LogisticRegression\n",
        "from   sklearn.tree import DecisionTreeClassifier\n",
        "from   sklearn.ensemble import RandomForestClassifier\n",
        "from   xgboost import XGBClassifier\n",
        "from   lightgbm import LGBMClassifier\n",
        "from   imblearn.over_sampling import RandomOverSampler\n",
        "import pickle\n",
        "\n",
        "# Maths\n",
        "import math\n",
        "\n",
        "# Set pandas options to show more rows and columns\n",
        "pd.set_option('display.max_rows', 800)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "NbgwzE12af1g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Churn_Modelling_m.csv\")"
      ],
      "metadata": {
        "id": "vkXJjY_0ausX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "iV3f1J_ma1vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "3CXRLON4a4pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "RWd_n99Ua7FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "T7B2QSdRa_tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datatile"
      ],
      "metadata": {
        "id": "Eq7_t-URbC8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datatile.summary.df import DataFrameSummary\n",
        "# Test with first few rows\n",
        "try:\n",
        "    dfs_small = DataFrameSummary(df.head(100))\n",
        "    print(\"Success with a smaller subset\")\n",
        "except Exception as e:\n",
        "    print(\"Error with a smaller subset:\", str(e))\n",
        "\n",
        "# Test with specific columns\n",
        "try:\n",
        "    dfs_numeric = DataFrameSummary(df.select_dtypes(include=[np.number]))\n",
        "    print(\"Success with numeric columns only\")\n",
        "except Exception as e:\n",
        "    print(\"Error with numeric columns:\", str(e))\n",
        "\n"
      ],
      "metadata": {
        "id": "kYvME67Ub8PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert object columns that should be categorical\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "# Convert strings to numbers where applicable\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')  # 'coerce' turns errors into NaNs\n",
        "\n",
        "try:\n",
        "    dfs = DataFrameSummary(df)\n",
        "    print(\"Initialization successful after type conversion.\")\n",
        "except Exception as e:\n",
        "    print(\"Still failing after type conversion:\", str(e))\n"
      ],
      "metadata": {
        "id": "ngtQovLEd5Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude categorical columns explicitly\n",
        "df_numeric = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Attempt to initialize DataFrameSummary with only numeric columns\n",
        "try:\n",
        "    dfs_numeric = DataFrameSummary(df_numeric)\n",
        "    print(\"Successfully initialized DataFrameSummary with numeric columns only.\")\n",
        "except Exception as e:\n",
        "    print(\"Error initializing with numeric columns:\", e)\n"
      ],
      "metadata": {
        "id": "3Bb9tUDbeV5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical columns to 'category' data type\n",
        "df['Gender'] = df['Gender'].astype('category')\n",
        "df['Geography'] = df['Geography'].astype('category')  # Assuming 'Geography' is also categorical\n",
        "\n",
        "try:\n",
        "    dfs = DataFrameSummary(df)\n",
        "    print(\"DataFrameSummary initialized successfully with categorical conversions.\")\n",
        "except Exception as e:\n",
        "    print(\"Error after converting to categorical:\", e)\n"
      ],
      "metadata": {
        "id": "wRze_cpHebFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with only numeric columns and one categorical column explicitly marked\n",
        "test_df = df[['CreditScore', 'Age', 'Gender']]\n",
        "test_df['Gender'] = test_df['Gender'].astype('category')\n",
        "\n",
        "try:\n",
        "    dfs_test = DataFrameSummary(test_df)\n",
        "    print(\"Initialization successful with a small subset of columns.\")\n",
        "except Exception as e:\n",
        "    print(\"Failed with a small subset of columns:\", e)\n"
      ],
      "metadata": {
        "id": "9nSaG0MVezBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas_profiling\n",
        "\n"
      ],
      "metadata": {
        "id": "33hBUQVxfGnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c conda-forge pandas_profiling"
      ],
      "metadata": {
        "id": "H7E0CO7TfZaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydantic-settings"
      ],
      "metadata": {
        "id": "Agc9z0uMfdxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install pydantic --upgrade\n",
        "!pip install pandas_profiling --upgrade"
      ],
      "metadata": {
        "id": "ff5ciETCfsTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pydantic<2.0\""
      ],
      "metadata": {
        "id": "Vo-r2zVrfALL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from pandas_profiling import ProfileReport\n",
        "    print(\"pandas_profiling is ready to use.\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to import pandas_profiling after downgrading pydantic:\", e)\n",
        ""
      ],
      "metadata": {
        "id": "H2eP8RpagKTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ydata_profiling import ProfileReport"
      ],
      "metadata": {
        "id": "EGmWL_R1gkJ8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from   pandas import DataFrame\n",
        "\n",
        "# Data Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine Learning\n",
        "from   sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
        "from   sklearn.impute import SimpleImputer\n",
        "from   sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from   sklearn.linear_model import LogisticRegression\n",
        "from   sklearn.tree import DecisionTreeClassifier\n",
        "from   sklearn.ensemble import RandomForestClassifier\n",
        "from   xgboost import XGBClassifier\n",
        "from   lightgbm import LGBMClassifier\n",
        "from   imblearn.over_sampling import RandomOverSampler\n",
        "import pickle\n",
        "\n",
        "# Maths\n",
        "import math\n",
        "\n",
        "# Set pandas options to show more rows and columns\n",
        "pd.set_option('display.max_rows', 800)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "lsY-IFYBhATc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Churn_Modelling_m.csv\")"
      ],
      "metadata": {
        "id": "UqJqD61Ng45Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame\n",
        "profile = ProfileReport(df, title='Data Profiling Report', explorative=True)\n",
        "profile.to_widgets()  # Display the report within Jupyter or Google Colab"
      ],
      "metadata": {
        "id": "yoClU0wvgmi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input file name with path\n",
        "input_file_name = 'Churn_Modelling_m.csv'\n",
        "\n",
        "# Target class name\n",
        "input_target_class = \"Exited\"\n",
        "\n",
        "# Columns to be removed\n",
        "input_drop_col = \"CustomerId\"\n",
        "\n",
        "# Col datatype selection\n",
        "input_datatype_selection = 'auto'  # use auto if you don't want to provide column names by data type else use 'manual'\n",
        "\n",
        "# Categorical columns\n",
        "input_cat_columns = ['Surname', 'Geography', 'Gender', 'Gender', 'HasCrCard', 'IsActiveMember', 'Exited']\n",
        "\n",
        "# Numerical columns\n",
        "input_num_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "\n",
        "# Encoding technique\n",
        "input_encoding = 'LabelEncoder' # choose the encoding technique from 'LabelEncoder', 'OneHotEncoder', 'OrdinalEncoder' and 'FrequencyEncoder'\n",
        "\n",
        "# Handle missing value\n",
        "input_treat_missing_value = 'drop' # choose how to handle missing values from 'drop','inpute' and 'ignore'\n",
        "\n",
        "# Machine learning algorithm\n",
        "input_ml_algo = 'RandomForestClassifier' # choose the ML algorithm from 'LogisiticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier', 'XGBClassifier' and LGBMClassifier'"
      ],
      "metadata": {
        "id": "wwPPrSQ6h2nL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.memory_usage(deep=True).sum() / 1024**2"
      ],
      "metadata": {
        "id": "q_1JhK2wipmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':  # for integers\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:  # for floats.\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "metadata": {
        "id": "YmG-iLi4i4Yn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_o   = reduce_mem_usage(df)"
      ],
      "metadata": {
        "id": "ktRVDjRTi9Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_o.info()"
      ],
      "metadata": {
        "id": "QBxaKLAhjAjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.memory_usage(deep=True).sum() / 1024**2"
      ],
      "metadata": {
        "id": "xI6U-QvDjEue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check distribution of target class\n",
        "sns.countplot(y=df[input_target_class] ,data=df)\n",
        "plt.xlabel(\"Count of each Target class\")\n",
        "plt.ylabel(\"Target classes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QDTZUt22jQUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Exited'].value_counts())"
      ],
      "metadata": {
        "id": "gLx8GxDKjUbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of all the features\n",
        "df.hist(figsize=(15,12),bins = 15)\n",
        "plt.title(\"Features Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cwVWv_ESkI3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_cols = 3\n",
        "n_rows = math.ceil(len(input_num_columns)/n_cols)"
      ],
      "metadata": {
        "id": "-8fLKCMukRbL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " sns.set(font_scale=2)"
      ],
      "metadata": {
        "id": "8JvWwPdPkT0u"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of y variable corresponding to every x variable\n",
        "fig,ax = plt.subplots(nrows = n_rows, ncols = n_cols, figsize=(30,30))\n",
        "row = 0\n",
        "col = 0\n",
        "for i in input_num_columns:\n",
        "    if col > 2:\n",
        "        row += 1\n",
        "        col = 0\n",
        "    axes = ax[row,col]\n",
        "    sns.boxplot(x = df[input_target_class], y = df[i], ax = axes)\n",
        "    col += 1\n",
        "plt.tight_layout()\n",
        "plt.title(\"Individual Features by Class\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "URa7k_fgkaxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joypy"
      ],
      "metadata": {
        "id": "ViY_KZrykmmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import joypy; print(joypy.__version__)\""
      ],
      "metadata": {
        "id": "0gG24hTQksVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joypy\n",
        "varbls = ['Age','Tenure','CreditScore','Balance', 'EstimatedSalary']\n",
        "\n",
        "plt.figure(figsize=(10,2), dpi= 80)\n",
        "for i,var in enumerate(varbls):\n",
        "    joypy.joyplot(df, column=[var], by=\"Exited\", ylim='own', figsize=(16,5), color=['tomato', 'purple']);\n",
        "    plt.title(f\"{var} by 'Exited'\", fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mRplJLNlkv3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(font_scale=1)"
      ],
      "metadata": {
        "id": "IX7XJw57k4-1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pairplot with seaborn library\n",
        "plt.figure(figsize=(10,8), dpi= 80)\n",
        "sns.pairplot(df.loc[:, ['Exited', 'CreditScore', 'Tenure', 'Age', 'Balance']],\n",
        "             kind=\"scatter\", hue=\"Exited\", plot_kws=dict(s=80, edgecolor=\"white\", linewidth=2.5))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ieR13KErk8ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8), dpi= 80)\n",
        "sns.pairplot(df.loc[:, ['Exited', 'CreditScore', 'Tenure', 'Age', 'Balance']],\n",
        "             kind=\"reg\", hue=\"Exited\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fNv4rM38lKmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install missingno"
      ],
      "metadata": {
        "id": "DfnkHl39--Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno # to visualize missing value"
      ],
      "metadata": {
        "id": "RSLMW1gN_cmg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(df)"
      ],
      "metadata": {
        "id": "JB2m-tAp_gR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.heatmap(df)"
      ],
      "metadata": {
        "id": "Yy_EttHzCIok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Age'].notnull()].head()"
      ],
      "metadata": {
        "id": "jXyyknDLCPaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_app1 = df[(df['Age'].notnull()) & df['Balance'].notnull()]\n",
        "df_app1.shape"
      ],
      "metadata": {
        "id": "Ag8RmdjUCgQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Balance_0\"] = df[\"Balance\"].fillna(0)\n",
        "df[[\"Surname\", \"CreditScore\", \"Geography\", \"Gender\", \"Age\", \"Tenure\", \"Balance\", \"Balance_0\"]].head()"
      ],
      "metadata": {
        "id": "DvJDA4wBCsgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Gender.value_counts()"
      ],
      "metadata": {
        "id": "pPhWeYyXC2S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_frequent = df.Gender.value_counts().index[0]\n",
        "most_frequent"
      ],
      "metadata": {
        "id": "VhOoWgzkC-ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gender'].fillna(most_frequent).head(10)"
      ],
      "metadata": {
        "id": "GoT7Sb52DA5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gender'].fillna(\"Empty\")"
      ],
      "metadata": {
        "id": "f_4fkAA0DF6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_val = df['Balance'].mean()\n",
        "df['Balance'].fillna(mean_val).head(10)"
      ],
      "metadata": {
        "id": "wyqofAxLDNFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean value by group\n",
        "df['Balance_by_Class'] = df.groupby('Gender')['Balance'].transform(lambda x: x.mean())\n",
        "df[['Gender', 'Balance', 'Balance_by_Class']].head(10)"
      ],
      "metadata": {
        "id": "tnPhYXQRDQDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Balance_imputed'] = np.where(np.isnan(df['Balance']), df['Balance_by_Class'], df['Balance'])\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "XR4oU64IDTCS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}